{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "saliency_maps.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNQiSujBfjWj"
      },
      "source": [
        "# saliency maps\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDHISSfBq40T"
      },
      "source": [
        "### downloads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Laatr1c6lr1w"
      },
      "source": [
        "!wget -O cat1.jpg https://storage.googleapis.com/laurencemoroney-blog.appspot.com/MLColabImages/cat1.jpg\n",
        "!wget -O cat2.jpg https://storage.googleapis.com/laurencemoroney-blog.appspot.com/MLColabImages/cat2.jpg\n",
        "!wget -O catanddog.jpg https://storage.googleapis.com/laurencemoroney-blog.appspot.com/MLColabImages/catanddog.jpg\n",
        "!wget -O dog1.jpg https://storage.googleapis.com/laurencemoroney-blog.appspot.com/MLColabImages/dog1.jpg\n",
        "!wget -O dog2.jpg https://storage.googleapis.com/laurencemoroney-blog.appspot.com/MLColabImages/dog2.jpg\n",
        "\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1kipXTxesGJKGY1B8uSPRvxROgOH90fih' -O 0_epochs.h5\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1oiV6tjy5k7h9OHGTQaf0Ohn3FmF-uOs1' -O 15_epochs.h5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g24L3lKwqb3E"
      },
      "source": [
        "### imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X86LKLvpBO2S"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import keras\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,GlobalAveragePooling2D\n",
        "from google.colab import drive, files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "th4dA3I8-9Ue"
      },
      "source": [
        "### download and prepare the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w5HNdoHBQv_"
      },
      "source": [
        "train_data = tfds.load('cats_vs_dogs', split='train[:80%]', as_supervised=True)\n",
        "validation_data = tfds.load('cats_vs_dogs', split='train[80%:90%]', as_supervised=True)\n",
        "test_data = tfds.load('cats_vs_dogs', split='train[-10%:]', as_supervised=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXp0mV5Rbo76"
      },
      "source": [
        "#### preprocessing function.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRkrL2aK2_UZ"
      },
      "source": [
        "def augmentimages(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image = (image / 255)\n",
        "  image = tf.image.resize(image, (300, 300))\n",
        "  return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzvF61GV32k_"
      },
      "source": [
        "#### preprocess the training set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpNEfDKM353a"
      },
      "source": [
        "augmented_training_data = train_data.map(augmentimages)\n",
        "augmented_test_data = test_data.map(augmentimages)\n",
        "augmented_validation_data = validation_data.map(augmentimages)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4nFaMIMbrvA"
      },
      "source": [
        "#### create batches of the training set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POhDDPBY3vnL"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "train_batches = augmented_training_data.batch(BATCH_SIZE)\n",
        "test_batches = augmented_test_data.batch(BATCH_SIZE)\n",
        "validation_batches = augmented_validation_data.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za5HxgT1_Cw6"
      },
      "source": [
        "### cats vs dogs classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoyCA80GBSlG"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(16, input_shape=(300, 300, 3), kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32,kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3,3 ), activation='relu', padding='same'))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6nou82P_b5d"
      },
      "source": [
        "### function to generate the saliency map."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKbvh3bl9vnG"
      },
      "source": [
        "def do_salience(image, model, label, prefix):\n",
        "  img = cv2.imread(image)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  img = cv2.resize(img, (300, 300)) / 255.0\n",
        "  tensor_image = np.expand_dims(img, axis=0)\n",
        "\n",
        "  num_classes = 2\n",
        "  expected_output = tf.one_hot([label] * tensor_image.shape[0], num_classes)\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    inputs = tf.cast(tensor_image, tf.float32)\n",
        "    tape.watch(inputs)\n",
        "    predictions = model(inputs)\n",
        "    loss = tf.keras.losses.categorical_crossentropy(\n",
        "        expected_output, predictions\n",
        "    )\n",
        "\n",
        "  gradients = tape.gradient(loss, inputs)\n",
        "  grayscale_tensor = tf.reduce_sum(tf.abs(gradients), axis=-1)\n",
        "  normalized_tensor = tf.cast(\n",
        "    255\n",
        "    * (grayscale_tensor - tf.reduce_min(grayscale_tensor))\n",
        "    / (tf.reduce_max(grayscale_tensor) - tf.reduce_min(grayscale_tensor)),\n",
        "    tf.uint8,\n",
        ")\n",
        "\n",
        "  normalized_tensor = tf.squeeze(normalized_tensor)\n",
        "\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.axis('off')\n",
        "  plt.imshow(normalized_tensor, cmap='gray')\n",
        "  plt.show()\n",
        "\n",
        "  gradient_color = cv2.applyColorMap(normalized_tensor.numpy(), cv2.COLORMAP_HOT)\n",
        "  gradient_color = gradient_color / 255.0\n",
        "  super_imposed = cv2.addWeighted(img, 0.5, gradient_color, 0.5, 0.0)\n",
        "\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.imshow(super_imposed)\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  salient_image_name = prefix + image\n",
        "  normalized_tensor = tf.expand_dims(normalized_tensor, -1)\n",
        "  normalized_tensor = tf.io.encode_jpeg(normalized_tensor, quality=100, format='grayscale')\n",
        "  writer = tf.io.write_file(salient_image_name, normalized_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## generate saliency maps with untrained model."
      ],
      "metadata": {
        "id": "xFQWF-J9zrdR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k39fF4n8fgG0"
      },
      "source": [
        "model.load_weights('0_epochs.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "do_salience(\"catanddog.jpg\", model, 0, \"epoch0_salient\")"
      ],
      "metadata": {
        "id": "yWdLxYb0wA8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZhZgd0x_JvN"
      },
      "source": [
        "### configure the model for training."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rms_prop = tf.keras.optimizers.RMSprop(\n",
        "    learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n",
        "    name='RMSprop')"
      ],
      "metadata": {
        "id": "1_Sdx3JzxYvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkyWZ5KdBo-z"
      },
      "source": [
        "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otIoJJw7_ZFN"
      },
      "source": [
        "### train model."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### mount google drive."
      ],
      "metadata": {
        "id": "3msrF68L0C2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "id": "woK4EYxfygND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_filepath = '/content/drive/My Drive/coursera/saliency_maps/model.ckpt'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_filepath, \n",
        "                                                               monitor='accuracy', mode='max', save_best_only=True)"
      ],
      "metadata": {
        "id": "7VVI9yuoyjI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### load model weights."
      ],
      "metadata": {
        "id": "yjE83oLy0D11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('15_epochs.h5')"
      ],
      "metadata": {
        "id": "Z6D2thk90N5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(checkpoint_filepath)"
      ],
      "metadata": {
        "id": "B75TfHXOyhS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YSNp7k7BqfL"
      },
      "source": [
        "EPOCHS = 100\n",
        "\n",
        "steps_per_epoch = len(train_batches) // BATCH_SIZE\n",
        "validation_steps = len(validation_batches) // BATCH_SIZE\n",
        "test_steps = len(test_batches) // BATCH_SIZE\n",
        "\n",
        "history = model.fit(train_batches,\n",
        "                    steps_per_epoch=steps_per_epoch, validation_data=validation_batches, \n",
        "                    validation_steps=validation_steps, epochs=EPOCHS,\n",
        "                    callbacks=[model_checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tTqtLN3tQJx"
      },
      "source": [
        "### generate saliency maps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXFtabyVhIKN"
      },
      "source": [
        "do_salience(\"cat1.jpg\", model, 1, \"salient\")\n",
        "do_salience(\"cat2.jpg\", model, 2, \"salient\")\n",
        "do_salience(\"catanddog.jpg\", model, 0, \"salient\")\n",
        "do_salience(\"dog1.jpg\", model, 3, \"salient\")\n",
        "do_salience(\"dog2.jpg\", model, 4, \"salient\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPtx-u4u_jL5"
      },
      "source": [
        "### zip the images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-MhcA8Uh8H_"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "!rm images.zip\n",
        "\n",
        "filenames = ['cat1.jpg', 'cat2.jpg', 'catanddog.jpg', 'dog1.jpg', 'dog2.jpg']\n",
        "\n",
        "with ZipFile('images.zip','w') as zip:\n",
        "  for file in filenames:\n",
        "    zip.write('salient' + file)\n",
        "\n",
        "print(\"images.zip generated!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMOgx-N55A6p"
      },
      "source": [
        "### saliency maps on 95 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elUfhSmMvJZh"
      },
      "source": [
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=14vFpBJsL_TNQeugX8vUTv8dYZxn__fQY' -O 95_epochs.h5\n",
        "\n",
        "model.load_weights('95_epochs.h5')\n",
        "\n",
        "do_salience('cat1.jpg', model, 0, \"epoch95_salient\")\n",
        "do_salience('cat2.jpg', model, 0, \"epoch95_salient\")\n",
        "do_salience('catanddog.jpg', model, 0, \"epoch95_salient\")\n",
        "do_salience('dog1.jpg', model, 1, \"epoch95_salient\")\n",
        "do_salience('dog2.jpg', model, 1, \"epoch95_salient\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuKLdQhvAaTd"
      },
      "source": [
        "## References\n",
        "##### Coursera - Advanced computer vision with tensorflow [course](https://www.coursera.org/learn/advanced-computer-vision-with-tensorflow/)."
      ]
    }
  ]
}